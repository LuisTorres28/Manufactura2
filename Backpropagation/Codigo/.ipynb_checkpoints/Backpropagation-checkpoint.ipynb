{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188589f0-7fa4-4e57-86fe-75025c129133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class perceptron:\n",
    "    def __init__(self,n,beta,bias,name='default'):\n",
    "        pesos      = beta*np.ones(n)\n",
    "        pesos      = np.concatenate((pesos,np.array([bias])))\n",
    "        self.n     = n\n",
    "        self.name  = name\n",
    "        self.pesos = pesos\n",
    "    \n",
    "    def Evaluar(self,entradas):\n",
    "        ##########################################################################\n",
    "        #   La función de activación del perceptron será la función \"Sigmoide\"   #\n",
    "        #                      sigmoide = 1 / ( 1 + e^{-S} )                     #\n",
    "        ##########################################################################\n",
    "        S     = self.pesos.dot(entradas)\n",
    "        sigma = 1 / ( 1 + np.exp(-S) )\n",
    "        return sigma\n",
    "\n",
    "class NeuralNet:\n",
    "    def __init__(self,layersShape,initialize,bias,InSize,InAll,name='Perc'):\n",
    "        size  = len(layersShape)\n",
    "        Net   = np.resize( np.array( [] , dtype = perceptron), size)\n",
    "        count = 0\n",
    "        nIn   = InSize\n",
    "        Grad  = [ ]\n",
    "        for i,nPerc in enumerate(layersShape):\n",
    "            layer  = [ ]\n",
    "            ini    = np.random.rand(nPerc) if initialize == 'random' else [initialize]*nPerc\n",
    "            Bias   = np.random.rand(nPerc) if bias == 'random' else [bias]*nPerc\n",
    "            Gradi  = [ ]\n",
    "            for j in range(nPerc):\n",
    "                layer += [perceptron(nIn,ini[j],Bias[j],f'{name}_layer{i}_perc{count}')]\n",
    "                count += 1\n",
    "                Gradij = [0]*(nIn + 1)\n",
    "                Gradi += [ Gradij ]\n",
    "            Grad  += [ Gradi ]\n",
    "            Net[i] = layer\n",
    "            nIn    = nPerc + InSize if ( InAll and i == ( size - 2 ) ) else nPerc\n",
    "        self.layers      = Net\n",
    "        self.layersShape = layersShape\n",
    "        self.nlayers     = size\n",
    "        self.nNodes      = count\n",
    "        self.InAll       = InAll\n",
    "        self.name        = name\n",
    "        self.InSize      = InSize\n",
    "        self.Grad        = Grad\n",
    "    \n",
    "    def Evaluar(self,In):\n",
    "        shape = self.layersShape\n",
    "        size  = self.nlayers\n",
    "        Net   = self.layers\n",
    "        InAll = self.InAll\n",
    "        IN    = [In]\n",
    "        OUT   = []\n",
    "        for i,nPerc in enumerate(shape):\n",
    "            Outi  = []\n",
    "            IN[i] = IN[i] + [1]  # Se agrega \"1\" al vector de entrada, que representa la entrada para el \"bias\"\n",
    "            for j in range(nPerc):\n",
    "                Outi += [Net[i][j].Evaluar(IN[i])]\n",
    "            IN   += [Outi + In] if ( InAll and i == ( size - 2 ) ) else [Outi]\n",
    "            OUT  += [Outi]\n",
    "        self.layersOut = OUT\n",
    "        self.layersIn  = IN\n",
    "        return OUT[-1]\n",
    "    \n",
    "    def Train(self,epocas,lr,DataSet,BatchSize=1):\n",
    "        print('\\n\\n'+'\\033[1m' + f'Entrenamiento de la red {self.name}' + '\\033[0m' + '\\n')\n",
    "        MSE   = []\n",
    "        Conv  = False\n",
    "        Convi = 0\n",
    "        Grad  = self.Grad\n",
    "        for i in range(epocas):\n",
    "            MSEi   = 0\n",
    "            nBatch = 0\n",
    "            conv   = []\n",
    "            k      = 0\n",
    "            for j,[In,Out] in enumerate(DataSet):\n",
    "                yd      = np.array(Out)\n",
    "                y       = np.array(self.Evaluar(In))\n",
    "                Grad    = self.Backpropagation(yd,Grad)\n",
    "                nBatch += 1\n",
    "                if nBatch == BatchSize:\n",
    "                    self.UpdateWeights(nBatch,lr,Grad)\n",
    "                    nBatch = 0\n",
    "                    k      = j\n",
    "                    Grad   = [ [ [ 0 for c in b ] for b in a ] for a in Grad]\n",
    "                elif j == len(DataSet)-1:\n",
    "                    self.UpdateWeights(nBatch,lr,Grad)\n",
    "                    Grad   = [ [ [ 0 for c in b ] for b in a ] for a in Grad]\n",
    "                error   = np.linalg.norm(yd - y)\n",
    "                conv   += [True] if error <= 0.05 else [False]\n",
    "                MSEi   += 0.5*error**2\n",
    "            # Verificar si cumple el criterio de convergencia de error <= 0.1\n",
    "            if not Conv:\n",
    "                Conv = True\n",
    "                for co in conv:\n",
    "                    Conv = Conv and co\n",
    "                if Conv:\n",
    "                    print(f'Convergencia en \\033[1mepoca {i}\\033[0m')\n",
    "                    Convi = i\n",
    "                    break\n",
    "            MSE   += [MSEi/j]\n",
    "        if not Conv:\n",
    "            print(f'No convergencia en {epocas} epocas')\n",
    "        self.Grad = Grad\n",
    "        return MSE, Convi\n",
    "    \n",
    "    def Backpropagation(self,yd,grad):\n",
    "        #a       = 1/nbatch\n",
    "        shape   = self.layersShape\n",
    "        nlayers = self.nlayers\n",
    "        Net     = self.layers\n",
    "        InAll   = self.InAll\n",
    "        Out     = self.layersOut\n",
    "        In      = self.layersIn\n",
    "        \n",
    "        #########################################\n",
    "        # Obtener los valores \"delta\" de la red #\n",
    "        #########################################\n",
    "        \n",
    "        Grad   = grad\n",
    "        delta  = [ [ ] ]*nlayers\n",
    "        Err    = np.array(yd) - np.array(Out[-1])\n",
    "        error  = [*Err]\n",
    "        for i,nPerc in reversed(list(enumerate(shape))): # Iterar sobre las capas de la red\n",
    "            deltai = []\n",
    "            errori = []\n",
    "            for j in range(nPerc): # Iterar sobre las \"neuronas\" de la capa i\n",
    "                deltaij  = error[j]*Out[i][j]*(1-Out[i][j])\n",
    "                deltai  += [deltaij]\n",
    "            delta[i] = deltai\n",
    "            for k in range(Net[i][0].pesos.size-1): # Iterar sobre cada uno de los pesos de la neurona ij\n",
    "                errorij = 0\n",
    "                for j in range(nPerc): # Iterar sobre las \"neuronas\" de la capa i\n",
    "                    errorij += deltai[j]*Net[i][j].pesos[k]\n",
    "                errori += [errorij]\n",
    "            error  = errori\n",
    "        for i,nPerc in enumerate(shape):\n",
    "            for j in range(nPerc):\n",
    "                for k in range(Net[i][j].pesos.size):\n",
    "                    #Net[i][j].pesos[k] += a*lr*delta[i][j]*In[i][k]\n",
    "                    Grad[i][j][k] += delta[i][j]*In[i][k]\n",
    "        self.layers = Net\n",
    "        return Grad\n",
    "    \n",
    "    def UpdateWeights(self,Batch,lr,Grad):\n",
    "        a     = (1/Batch)\n",
    "        Net   = self.layers\n",
    "        In    = self.layersIn\n",
    "        shape = self.layersShape\n",
    "        \n",
    "        ##############################################\n",
    "        #       Actualizar los pesos de la red       #\n",
    "        ##############################################\n",
    "        for i,nPerc in enumerate(shape):\n",
    "            for j in range(nPerc):\n",
    "                for k in range(Net[i][j].pesos.size):\n",
    "                    Net[i][j].pesos[k] += a*lr*Grad[i][j][k]\n",
    "        self.layers = Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a10fa2e-7a07-4f21-9b15-a4ebb62a172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0001n\u0001n************************************************************************************************************\n",
      "************************************************************************************************************\n",
      "*************************        \u001b[1mOrden de entrenamiento 1\u001b[0m        *************************\n",
      "************************************************************************************************************\n",
      "************************************************************************************************************\n",
      "**************************************************************************************************\n",
      "Evaluación de las redes neuronales para la compuerta logica \"And\", \"Or\" y \"Xor\" sin entrenamiento\n",
      "**************************************************************************************************\n",
      "\u001b[1m         And                   Or               Xor\u001b[0m\n",
      "1: [0, 0] ... 0.8   |   [0, 0] ... 0.8   |   [0, 0] ... 0.8\n",
      "2: [0, 1] ... 0.9   |   [0, 1] ... 0.9   |   [0, 1] ... 0.8\n",
      "3: [1, 0] ... 0.9   |   [1, 0] ... 0.9   |   [1, 0] ... 0.8\n",
      "4: [1, 1] ... 1.0   |   [1, 1] ... 0.9   |   [1, 1] ... 0.9\n",
      "\n",
      "***********************************\n",
      "\u001b[1mEntrenamiento de las redes\u001b[0m\n",
      "***********************************\n",
      "\\Orden de dataset: 1\n",
      "Tasa de aprendizaje: 0.1\n",
      "Peso inicial: random\n",
      "Bias: 1\n",
      "Epocas de entrenamiento: 50000\n",
      "Batch: 1\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red And\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 7516\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Or\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 11395\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Xor\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 22173\u001b[0m\n",
      "\n",
      "********************************************************************************************************\n",
      "Evaluación de las redes para la compuerta logica \"And\", \"Or\" y \"Xor\" con entrenamiento\n",
      "********************************************************************************************************\n",
      "\u001b[1m         And                   Or               Xor\u001b[0m\n",
      "1: [0, 0] ... 0.0   |   [0, 0] ... 0.0   |   [0, 0] ... 0.0\n",
      "2: [0, 1] ... 0.0   |   [0, 1] ... 1.0   |   [0, 1] ... 1.0\n",
      "3: [1, 0] ... 0.0   |   [1, 0] ... 1.0   |   [1, 0] ... 1.0\n",
      "4: [1, 1] ... 1.0   |   [1, 1] ... 1.0   |   [1, 1] ... 0.0\n",
      "\n",
      "***********************************\n",
      "\u001b[1mEntrenamiento de las redes\u001b[0m\n",
      "***********************************\n",
      "\\Orden de dataset: 1\n",
      "Tasa de aprendizaje: 0.5\n",
      "Peso inicial: random\n",
      "Bias: 1\n",
      "Epocas de entrenamiento: 50000\n",
      "Batch: 1\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red And\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 2625\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Or\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 1732\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Xor\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 6874\u001b[0m\n",
      "\n",
      "********************************************************************************************************\n",
      "Evaluación de las redes para la compuerta logica \"And\", \"Or\" y \"Xor\" con entrenamiento\n",
      "********************************************************************************************************\n",
      "\u001b[1m         And                   Or               Xor\u001b[0m\n",
      "1: [0, 0] ... 0.0   |   [0, 0] ... 0.0   |   [0, 0] ... 0.0\n",
      "2: [0, 1] ... 0.0   |   [0, 1] ... 1.0   |   [0, 1] ... 1.0\n",
      "3: [1, 0] ... 0.0   |   [1, 0] ... 1.0   |   [1, 0] ... 1.0\n",
      "4: [1, 1] ... 1.0   |   [1, 1] ... 1.0   |   [1, 1] ... 0.0\n",
      "\n",
      "***********************************\n",
      "\u001b[1mEntrenamiento de las redes\u001b[0m\n",
      "***********************************\n",
      "\\Orden de dataset: 1\n",
      "Tasa de aprendizaje: 1\n",
      "Peso inicial: random\n",
      "Bias: 1\n",
      "Epocas de entrenamiento: 50000\n",
      "Batch: 1\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red And\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 707\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Or\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 1121\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Xor\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 2905\u001b[0m\n",
      "\n",
      "********************************************************************************************************\n",
      "Evaluación de las redes para la compuerta logica \"And\", \"Or\" y \"Xor\" con entrenamiento\n",
      "********************************************************************************************************\n",
      "\u001b[1m         And                   Or               Xor\u001b[0m\n",
      "1: [0, 0] ... 0.0   |   [0, 0] ... 0.0   |   [0, 0] ... 0.0\n",
      "2: [0, 1] ... 0.0   |   [0, 1] ... 1.0   |   [0, 1] ... 1.0\n",
      "3: [1, 0] ... 0.0   |   [1, 0] ... 1.0   |   [1, 0] ... 1.0\n",
      "4: [1, 1] ... 1.0   |   [1, 1] ... 1.0   |   [1, 1] ... 0.0\n",
      "\n",
      "***********************************\n",
      "\u001b[1mEntrenamiento de las redes\u001b[0m\n",
      "***********************************\n",
      "\\Orden de dataset: 1\n",
      "Tasa de aprendizaje: 2\n",
      "Peso inicial: random\n",
      "Bias: 1\n",
      "Epocas de entrenamiento: 50000\n",
      "Batch: 1\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red And\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 639\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Or\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 482\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Xor\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 1463\u001b[0m\n",
      "\n",
      "********************************************************************************************************\n",
      "Evaluación de las redes para la compuerta logica \"And\", \"Or\" y \"Xor\" con entrenamiento\n",
      "********************************************************************************************************\n",
      "\u001b[1m         And                   Or               Xor\u001b[0m\n",
      "1: [0, 0] ... 0.0   |   [0, 0] ... 0.0   |   [0, 0] ... 0.0\n",
      "2: [0, 1] ... 0.0   |   [0, 1] ... 1.0   |   [0, 1] ... 1.0\n",
      "3: [1, 0] ... 0.0   |   [1, 0] ... 1.0   |   [1, 0] ... 1.0\n",
      "4: [1, 1] ... 1.0   |   [1, 1] ... 1.0   |   [1, 1] ... 0.0\n",
      "\n",
      "***********************************\n",
      "\u001b[1mEntrenamiento de las redes\u001b[0m\n",
      "***********************************\n",
      "\\Orden de dataset: 1\n",
      "Tasa de aprendizaje: 3\n",
      "Peso inicial: random\n",
      "Bias: 1\n",
      "Epocas de entrenamiento: 50000\n",
      "Batch: 1\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red And\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 417\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Or\u001b[0m\n",
      "\n",
      "Convergencia en \u001b[1mepoca 296\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Xor\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2452\\107944823.py\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mMSE_Andi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAnd_Convi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepocas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataset_And\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mMSE_Ori\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOr_Convi\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mOr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepocas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataset_Or\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mMSE_Xori\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXor_Convi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepocas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDataset_Xor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mMSE_And\u001b[0m  \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mMSE_Andi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2452\\2084650198.py\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self, epocas, lr, DataSet, BatchSize)\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0myd\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0my\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvaluar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                 \u001b[0mGrad\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBackpropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m                 \u001b[0mnBatch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnBatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mBatchSize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2452\\2084650198.py\u001b[0m in \u001b[0;36mBackpropagation\u001b[1;34m(self, yd, grad)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mGrad\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mdelta\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0mErr\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0merror\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mErr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnPerc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Iterar sobre las capas de la red\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr     = [0.1,0.5,1,2,3,4,5]\n",
    "epocas = 50000\n",
    "wi     = 'random'\n",
    "bias   = 1\n",
    "conAll = True\n",
    "Batchs = [1,2,4]\n",
    "shape  = (1,1) # Forma de la red (capas y neuronas por cada capa)\n",
    "\n",
    "# Leyendas para graficas de aprendizaje\n",
    "PlotLegend = [r'$\\alpha=0.1$',r'$\\alpha=0.5$',r'$\\alpha=1$',r'$\\alpha=2$',r'$\\alpha=3$',r'$\\alpha=4$',r'$\\alpha=5$',]\n",
    "\n",
    "####################################################################\n",
    "###    Generar los dataset para el entrenamiento de las redes    ###\n",
    "####################################################################\n",
    "IN           = [[0 , 0] , [0 , 1] , [1 , 0] , [1 , 1]]\n",
    "Dataset1_And = [[IN[0], [0]] , [IN[1], [0]] , [IN[2], [0]] , [IN[3], [1]]]\n",
    "Dataset1_Or  = [[IN[0], [0]] , [IN[1], [1]] , [IN[2], [1]] , [IN[3], [1]]]\n",
    "Dataset1_Xor = [[IN[0], [0]] , [IN[1], [1]] , [IN[2], [1]] , [IN[3], [0]]]\n",
    "Dataset2_And = [[IN[3], [1]] , [IN[2], [0]] , [IN[1], [0]] , [IN[0], [0]]]\n",
    "Dataset2_Or  = [[IN[3], [1]] , [IN[2], [1]] , [IN[1], [1]] , [IN[0], [0]]]\n",
    "Dataset2_Xor = [[IN[3], [0]] , [IN[2], [1]] , [IN[1], [1]] , [IN[0], [0]]]\n",
    "Dataset3_And = [[IN[0], [0]] , [IN[3], [1]] , [IN[1], [0]] , [IN[2], [0]]]\n",
    "Dataset3_Or  = [[IN[0], [0]] , [IN[3], [1]] , [IN[1], [1]] , [IN[2], [1]]]\n",
    "Dataset3_Xor = [[IN[0], [0]] , [IN[3], [0]] , [IN[1], [1]] , [IN[2], [1]]]\n",
    "\n",
    "Dataset  = []\n",
    "Dataset += [ [ Dataset1_And , Dataset1_Or , Dataset1_Xor ] ]\n",
    "Dataset += [ [ Dataset2_And , Dataset2_Or , Dataset2_Xor ] ]\n",
    "Dataset += [ [ Dataset3_And , Dataset3_Or , Dataset3_Xor ] ]\n",
    "\n",
    "for j,[Dataset_And , Dataset_Or , Dataset_Xor] in enumerate(Dataset):\n",
    "    print(f'\\1n\\1n************************************************************************************************************')\n",
    "    print(f'************************************************************************************************************')\n",
    "    print(f'*************************        \\033[1mOrden de entrenamiento {j+1}\\033[0m        *************************')\n",
    "    print(f'************************************************************************************************************')\n",
    "    print(f'************************************************************************************************************')\n",
    "\n",
    "    ######################################################################\n",
    "    ###                  Crear las redes neuronales                    ###\n",
    "    ###           Evaluación inicial de las redes neuronales           ###\n",
    "    ######################################################################\n",
    "\n",
    "    And = NeuralNet(shape,wi,bias,2,conAll,'And')\n",
    "    Or  = NeuralNet(shape,wi,bias,2,conAll,'Or')\n",
    "    Xor = NeuralNet(shape,wi,bias,2,conAll,'Xor')\n",
    "\n",
    "    print('**************************************************************************************************')\n",
    "    print(f'Evaluación de las redes neuronales para la compuerta logica \"And\", \"Or\" y \"Xor\" sin entrenamiento')\n",
    "    print('**************************************************************************************************')\n",
    "    print('\\033[1m' + f'         And                   Or               Xor' + '\\033[0m')\n",
    "    for i,[In,Out] in enumerate(Dataset_And):\n",
    "        a  = And.Evaluar(In)\n",
    "        b  = Or.Evaluar(In)\n",
    "        c  = Xor.Evaluar(In)\n",
    "        print(f'{i+1}: {In} ... {a[0]:.1f}   |   {In} ... {b[0]:.1f}   |   {In} ... {c[0]:.1f}')\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    ###             Entrenamiento de las redes neuronales             ###\n",
    "    #####################################################################\n",
    "    for Batch in Batchs:\n",
    "        # Almacenar la epoca en la que converge la red en su entrenamiento\n",
    "        And_Conv = [ ]\n",
    "        Or_Conv  = [ ]\n",
    "        Xor_Conv = [ ]\n",
    "        MSE_And  = [ ]\n",
    "        MSE_Or   = [ ]\n",
    "        MSE_Xor  = [ ]\n",
    "        for lri in lr:\n",
    "            And = NeuralNet(shape,wi,bias,2,conAll,'And')\n",
    "            Or  = NeuralNet(shape,wi,bias,2,conAll,'Or')\n",
    "            Xor = NeuralNet(shape,wi,bias,2,conAll,'Xor')\n",
    "\n",
    "            print(f'\\n***********************************\\n\\033[1mEntrenamiento de las redes\\033[0m\\n***********************************')\n",
    "            print(f'Orden de dataset: {j+1}\\nTasa de aprendizaje: {lri}\\nPeso inicial: {wi}\\nBias: {bias}\\nEpocas de entrenamiento: {epocas}\\nBatch: {Batch}')\n",
    "\n",
    "            ###############################################################\n",
    "            #  Backpropagation para generar la compuerta lógica And y Or  #\n",
    "            ###############################################################\n",
    "\n",
    "            MSE_Andi,And_Convi = And.Train(epocas,lri,Dataset_And,Batch)\n",
    "            MSE_Ori,Or_Convi   = Or.Train(epocas,lri,Dataset_Or,Batch)\n",
    "            MSE_Xori,Xor_Convi = Xor.Train(epocas,lri,Dataset_Xor,Batch)\n",
    "\n",
    "            MSE_And  += [MSE_Andi]\n",
    "            MSE_Or   += [MSE_Ori]\n",
    "            MSE_Xor  += [MSE_Xori]\n",
    "            And_Conv += [And_Convi]\n",
    "            Or_Conv  += [Or_Convi]\n",
    "            Xor_Conv += [Xor_Convi]\n",
    "\n",
    "            print('\\n********************************************************************************************************')\n",
    "            print(f'Evaluación de las redes para la compuerta logica \"And\", \"Or\" y \"Xor\" con entrenamiento')\n",
    "            print('********************************************************************************************************')\n",
    "            print('\\033[1m' + f'         And                   Or               Xor' + '\\033[0m')\n",
    "            for i,[In,Out] in enumerate(Dataset_And):\n",
    "                a  = And.Evaluar(In)\n",
    "                b  = Or.Evaluar(In)\n",
    "                c  = Xor.Evaluar(In)\n",
    "                print(f'{i+1}: {In} ... {a[0]:.1f}   |   {In} ... {b[0]:.1f}   |   {In} ... {c[0]:.1f}')\n",
    "\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.subplot(3,1,1)\n",
    "        for plot in MSE_And:\n",
    "            plt.plot(plot)\n",
    "            plt.legend(PlotLegend)\n",
    "        plt.grid()\n",
    "        plt.xlim((0,max(And_Conv)))\n",
    "        plt.subplot(3,1,2)\n",
    "        for plot in MSE_Or:\n",
    "            plt.plot(plot)\n",
    "            plt.legend(PlotLegend)\n",
    "        plt.grid()\n",
    "        plt.xlim((0,max(Or_Conv)))\n",
    "        plt.subplot(3,1,3)\n",
    "        for plot in MSE_Xor:\n",
    "            plt.plot(plot)\n",
    "            plt.legend(PlotLegend)\n",
    "        plt.grid()\n",
    "        plt.xlim((0,max(Xor_Conv)))\n",
    "        plt.savefig(f'Training Batch {Batch} Orden {j+1}.png')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
