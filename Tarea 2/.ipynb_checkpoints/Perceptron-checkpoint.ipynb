{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188589f0-7fa4-4e57-86fe-75025c129133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class perceptron:\n",
    "    def __init__(self,n,beta,bias,name='default'):\n",
    "        self.pesos = beta*np.ones(n)\n",
    "        self.n     = n\n",
    "        self.bias  = bias\n",
    "        self.w0    = beta\n",
    "        self.name  = name\n",
    "    \n",
    "    def Evaluar(self,entradas):\n",
    "        #######################################################################\n",
    "        #  La función de activación del perceptron será la función \"Escalon\"  #\n",
    "        #######################################################################\n",
    "        bias = self.bias\n",
    "        w0   = self.w0\n",
    "        return 1*((bias + self.pesos.dot(entradas)) > 0)\n",
    "    \n",
    "    def Backpropagation(self,alpha,yd,entradas,salida):\n",
    "        for i in range(self.n):\n",
    "            error         = yd - salida\n",
    "            self.pesos[i] = self.pesos[i] + alpha*(error)*entradas[i]\n",
    "        error     = yd - salida\n",
    "        self.bias = self.bias + alpha*(error)\n",
    "    \n",
    "    def Train(self,epocas,lr,DataIn,DataOutd):\n",
    "        print('\\n\\n'+'\\033[1m' + f'Entrenamiento de la red {self.name}' + '\\033[0m' + '\\n')\n",
    "        for i in range(epocas):\n",
    "            error = 0\n",
    "            for j,In in enumerate(DataIn):\n",
    "                yd    = DataOutd[j]\n",
    "                y     = self.Evaluar(In)\n",
    "                error += np.abs(yd - y)\n",
    "                self.Backpropagation(lr,yd,In,y)\n",
    "            conv  = \"\\033[1mConverge\\033[0m\" if error <= 0.1 else \"No Converge\"\n",
    "            print(f'Epoca {i+1} - Error: {error} ... {conv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a10fa2e-7a07-4f21-9b15-a4ebb62a172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************************************\n",
      "Evaluación del perceptron para la compuerta logica \"And\", \"Or\" y \"Xor\" sin entrenamiento\n",
      "***************************************************************************************\n",
      "\u001b[1m         And                 Or               Xor\u001b[0m\n",
      "1: [0, 0] ... 0   |   [0, 0] ... 0   |   [0, 0] ... 0\n",
      "2: [0, 1] ... 0   |   [0, 1] ... 0   |   [0, 1] ... 0\n",
      "3: [1, 0] ... 0   |   [1, 0] ... 0   |   [1, 0] ... 0\n",
      "4: [1, 1] ... 1   |   [1, 1] ... 1   |   [1, 1] ... 1\n",
      "\n",
      "***********************************\n",
      "\u001b[1mEntrenamiento de los perceptrones\u001b[0m\n",
      "***********************************\n",
      "Tasa de aprendizaje: 5\n",
      "Peso inicial: 0.9\n",
      "Bias: -1\n",
      "Epocas de entrenamiento: 20\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red And\u001b[0m\n",
      "\n",
      "Epoca 1 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 2 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 3 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 4 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 5 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 6 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 7 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 8 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 9 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 10 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 11 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 12 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 13 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 14 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 15 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 16 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 17 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 18 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 19 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 20 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Or\u001b[0m\n",
      "\n",
      "Epoca 1 - Error: 1 ... No Converge\n",
      "Epoca 2 - Error: 2 ... No Converge\n",
      "Epoca 3 - Error: 1 ... No Converge\n",
      "Epoca 4 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 5 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 6 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 7 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 8 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 9 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 10 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 11 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 12 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 13 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 14 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 15 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 16 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 17 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 18 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 19 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "Epoca 20 - Error: 0 ... \u001b[1mConverge\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEntrenamiento de la red Xor\u001b[0m\n",
      "\n",
      "Epoca 1 - Error: 2 ... No Converge\n",
      "Epoca 2 - Error: 3 ... No Converge\n",
      "Epoca 3 - Error: 4 ... No Converge\n",
      "Epoca 4 - Error: 4 ... No Converge\n",
      "Epoca 5 - Error: 4 ... No Converge\n",
      "Epoca 6 - Error: 4 ... No Converge\n",
      "Epoca 7 - Error: 4 ... No Converge\n",
      "Epoca 8 - Error: 4 ... No Converge\n",
      "Epoca 9 - Error: 4 ... No Converge\n",
      "Epoca 10 - Error: 4 ... No Converge\n",
      "Epoca 11 - Error: 4 ... No Converge\n",
      "Epoca 12 - Error: 4 ... No Converge\n",
      "Epoca 13 - Error: 4 ... No Converge\n",
      "Epoca 14 - Error: 4 ... No Converge\n",
      "Epoca 15 - Error: 4 ... No Converge\n",
      "Epoca 16 - Error: 4 ... No Converge\n",
      "Epoca 17 - Error: 4 ... No Converge\n",
      "Epoca 18 - Error: 4 ... No Converge\n",
      "Epoca 19 - Error: 4 ... No Converge\n",
      "Epoca 20 - Error: 4 ... No Converge\n",
      "\n",
      "****************************************************************************************************\n",
      "Evaluación del perceptron para la compuerta logica \"And\", \"Or\" y \"Xor\" con entrenamiento de 20 epocas\n",
      "****************************************************************************************************\n",
      "\u001b[1m         And                 Or               Xor\u001b[0m\n",
      "1: [0, 0] ... 0   |   [0, 0] ... 0   |   [0, 0] ... 1\n",
      "2: [0, 1] ... 0   |   [0, 1] ... 1   |   [0, 1] ... 1\n",
      "3: [1, 0] ... 0   |   [1, 0] ... 1   |   [1, 0] ... 0\n",
      "4: [1, 1] ... 1   |   [1, 1] ... 1   |   [1, 1] ... 1\n"
     ]
    }
   ],
   "source": [
    "lr     = 5\n",
    "epocas = 20\n",
    "wi     = 0.9\n",
    "bias   = -1\n",
    "\n",
    "And    = perceptron(2,wi,bias,'And')\n",
    "Or     = perceptron(2,wi,bias,'Or')\n",
    "Xor    = perceptron(2,wi,bias,'Xor')\n",
    "\n",
    "DataIn = [[0,0],[0,1],[1,0],[1,1]]\n",
    "AndOut = [0,0,0,1]\n",
    "OrOut  = [0,1,1,1]\n",
    "XorOut = [0,1,1,0]\n",
    "\n",
    "print('***************************************************************************************')\n",
    "print(f'Evaluación del perceptron para la compuerta logica \"And\", \"Or\" y \"Xor\" sin entrenamiento')\n",
    "print('***************************************************************************************')\n",
    "print('\\033[1m' + f'         And                 Or               Xor' + '\\033[0m')\n",
    "for i,In in enumerate(DataIn):\n",
    "    a  = And.Evaluar(In)\n",
    "    b  = Or.Evaluar(In)\n",
    "    c  = Xor.Evaluar(In)\n",
    "    print(f'{i+1}: {In} ... {a}   |   {In} ... {b}   |   {In} ... {c}')\n",
    "\n",
    "print(f'\\n***********************************\\n\\033[1mEntrenamiento de los perceptrones\\033[0m\\n***********************************')\n",
    "print(f'Tasa de aprendizaje: {lr}\\nPeso inicial: {wi}\\nBias: {bias}\\nEpocas de entrenamiento: {epocas}')\n",
    "\n",
    "###############################################################\n",
    "#  Backpropagation para generar la compuerta lógica And y Or  #\n",
    "###############################################################\n",
    "\n",
    "And.Train(epocas,lr,DataIn,AndOut)\n",
    "Or.Train(epocas,lr,DataIn,OrOut)\n",
    "Xor.Train(epocas,lr,DataIn,XorOut)\n",
    "\n",
    "print('\\n****************************************************************************************************')\n",
    "print(f'Evaluación del perceptron para la compuerta logica \"And\", \"Or\" y \"Xor\" con entrenamiento de {epocas} epocas')\n",
    "print('****************************************************************************************************')\n",
    "print('\\033[1m' + f'         And                 Or               Xor' + '\\033[0m')\n",
    "for i,In in enumerate(DataIn):\n",
    "    a  = And.Evaluar(In)\n",
    "    b  = Or.Evaluar(In)\n",
    "    c  = Xor.Evaluar(In)\n",
    "    print(f'{i+1}: {In} ... {a}   |   {In} ... {b}   |   {In} ... {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f5e33e-fada-42ff-bc92-848cc0a38a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And bias: -1\n",
      "Or bias: -1\n",
      "Xor bias: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'And bias: {And.bias}')\n",
    "print(f'Or bias: {Or.bias}')\n",
    "print(f'Xor bias: {Xor.bias}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543222f-104a-4082-838a-f062fb41e3ef",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "Se observa del desarrollo del perceptrón que, este es capaz de aprender los patrones existentes en los conjuntos de entrenamiento siempre y cuando estas diferencias sean \"_visibles_\", tal como es el caso del perceptrón para la compuerta lógica **Xor**, en donde las diferencias en sus conjunto de entrenamiento no son muy evidentes, ya que la activación se da con las combinaciones [1,0] y [0,1], las cuales son muy parecidas entre si. Para el caso de la compuerta **Xor** se requiere del uso de una red de perceptrones (Mejor conocida como red neuronal) de manera que toda la red en conjunto aprenda las caracterísitcas [0,1] y [1,0].  \n",
    "- Se puede entonces concluir que el perceptrón es una unidad de percepción minima que comopne a una red neuronal y que tiene la capacidad de identificar patrones dentro de un conjunto de datos, pero la limitante de que estos patrones deben tener razgos que sean relativamente faciles de diferenciar entre si, de otro modo el perceptrón por si solo no será capaz de aprender dichos patrones.\n",
    "- También se observó que los parámetros utilizados para crear el perceptrón tienen influencia en la convergencia a la hora del entrenamiento del perceptrón, ya que una solución inicial que se aproxime en mejor medida a los parámetros \"*ideales*\" del perceptrón permitira una convergencia más rápida a la solución adecuada, por otro lado, una solución inicial que se encuentre muy alejada de los parámetros \"*ideales*\" hara que el entrenamiento del perceptrón le tome mayor cantidad de epocas alcanzar una convergencia.\n",
    "- Al igual que la solución inicial es importante, también lo es el factor de aprendizaje o tasa de aprendizaje, ya que este permite acelerar o desacelerar la actualización de los valores hacia el valor adecuado de los pesos, pero también es importante que un valor de tasa de aprendizaje pequeño, provoca que tarde más una convergencia hacia los valores adecuados, mientras que un valor muy alto puede provocar una desestabilización o hacer que no se converga a un valor adecuado de los pesos del perceptrón.\n",
    "- Finalmente, la selección del bias también es importante, ya que este permite al perceptrón una mejor discerción de la información de entrada, por lo que su valor resulta importante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
